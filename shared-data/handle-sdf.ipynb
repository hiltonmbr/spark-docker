{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77af88dd",
   "metadata": {},
   "source": [
    "## Using Spark Cluster with shared data in Docker\n",
    "\n",
    "### Handle Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5969aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.5.3 in ./.venv/lib/python3.12/site-packages (3.5.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (78.1.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (24.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./.venv/lib/python3.12/site-packages (from pyspark==3.5.3) (0.10.9.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.5.3 pandas setuptools packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb38c7c",
   "metadata": {},
   "source": [
    "#### Download csv file to local directory (shared with spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from os import remove\n",
    "\n",
    "url = 'https://www.kaggle.com/api/v1/datasets/download/chaitanyahivlekar/large-movie-dataset'\n",
    "urllib.request.urlretrieve(url,'movies.zip')\n",
    "\n",
    "with zipfile.ZipFile('movies.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "\n",
    "remove('movies.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39e4d4",
   "metadata": {},
   "source": [
    "#### Connect to Spark Cluster and create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10aa2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/09 15:13:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyAppSDF\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c28c74",
   "metadata": {},
   "source": [
    "#### Read data\n",
    "##### Create a spark data frame from csv file\n",
    "\n",
    "To create a spark data frame from a csv file, we can use the `read.csv` function. Using `inferSchema=True` allow spark infer correct type for each field. However, it can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3180e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.csv(\"movies_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a796e",
   "metadata": {},
   "source": [
    "To see the schema, use `.printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8a02c",
   "metadata": {},
   "source": [
    "Let's show first rows of spark data frame with method `.show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdfb473",
   "metadata": {},
   "source": [
    "Count total of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca88944",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0b39d",
   "metadata": {},
   "source": [
    "#### Filter data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15920678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "sdf.filter(col(\"Rating\") >= 5 ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sdf.filter( (col(\"Rating\") >= 5) & col('Genre').contains(\"Comedy\") ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927643a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.filter( (col('Genre').contains(\"Action\")) | col('Genre').contains(\"Comedy\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_top = sdf.filter( (col(\"Rating\") >= 5) & col('Genre').contains(\"Comedy\") )\n",
    "sdf_top.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1ca8f",
   "metadata": {},
   "source": [
    "#### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a328b309",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdf_top' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m sf\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msdf_top\u001b[49m.groupBy(\u001b[33m\"\u001b[39m\u001b[33mMovie_name\u001b[39m\u001b[33m\"\u001b[39m).agg(\n\u001b[32m      4\u001b[39m     sf.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mtotal_ratings\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m ).show()\n",
      "\u001b[31mNameError\u001b[39m: name 'sdf_top' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "\n",
    "sdf_top.groupBy(\"Movie_name\").agg(\n",
    "    sf.count(\"*\").alias(\"total_ratings\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.filter( sf.col('Genre').contains(\"Comedy\") ). \\\n",
    "    groupBy(\"Movie_name\").agg(\n",
    "        sf.count(\"*\").alias(\"total_ratings\"),\n",
    "        sf.avg(\"Rating\").alias(\"avg_rating\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.filter( sf.col('Genre').contains(\"Comedy\") ). \\\n",
    "    groupBy(\"Movie_name\").agg(\n",
    "        sf.count(\"*\").alias(\"total_ratings\"),\n",
    "        sf.avg(\"Rating\").alias(\"avg_rating\"),\n",
    "        sf.sum(\"Rating\").alias(\"sum_rating\")\n",
    "    ). \\\n",
    "   orderBy(\"total_ratings\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762aa6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>total_ratings</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>sum_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>81491</td>\n",
       "      <td>4.048011</td>\n",
       "      <td>329876.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>79672</td>\n",
       "      <td>4.188912</td>\n",
       "      <td>333739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>47823</td>\n",
       "      <td>4.111421</td>\n",
       "      <td>196620.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>37863</td>\n",
       "      <td>4.129097</td>\n",
       "      <td>156340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monty Python and the Holy Grail (1975)</td>\n",
       "      <td>37723</td>\n",
       "      <td>4.147655</td>\n",
       "      <td>156462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Living on Love (1937)</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Born in Absurdistan (1999)</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Road to Kabul (2012)</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Junga (2018)</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Point, Point, Comma... (1972)</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Movie_name  total_ratings  avg_rating  \\\n",
       "0                       Forrest Gump (1994)          81491    4.048011   \n",
       "1                       Pulp Fiction (1994)          79672    4.188912   \n",
       "2                              Fargo (1996)          47823    4.111421   \n",
       "3                Princess Bride, The (1987)          37863    4.129097   \n",
       "4    Monty Python and the Holy Grail (1975)          37723    4.147655   \n",
       "..                                      ...            ...         ...   \n",
       "585                   Living on Love (1937)              1    5.000000   \n",
       "586              Born in Absurdistan (1999)              1    4.500000   \n",
       "587                    Road to Kabul (2012)              1    4.500000   \n",
       "588                            Junga (2018)              1    5.000000   \n",
       "589           Point, Point, Comma... (1972)              1    5.000000   \n",
       "\n",
       "     sum_rating  \n",
       "0      329876.5  \n",
       "1      333739.0  \n",
       "2      196620.5  \n",
       "3      156340.0  \n",
       "4      156462.0  \n",
       "..          ...  \n",
       "585         5.0  \n",
       "586         4.5  \n",
       "587         4.5  \n",
       "588         5.0  \n",
       "589         5.0  \n",
       "\n",
       "[590 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "\n",
    "df = sdf.filter( sf.col('Genre').contains(\"Comedy\") ). \\\n",
    "    groupBy(\"Movie_name\").agg(\n",
    "        sf.count(\"*\").alias(\"total_ratings\"),\n",
    "        sf.avg(\"Rating\").alias(\"avg_rating\"),\n",
    "        sf.sum(\"Rating\").alias(\"sum_rating\")\n",
    "    ). \\\n",
    "    filter( sf.col(\"avg_rating\") > 4). \\\n",
    "    orderBy(\"total_ratings\", ascending=False). \\\n",
    "    toPandas()\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
